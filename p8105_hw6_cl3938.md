Homework 6
================
Cynthia Liu (cl3938)

### Problem 1

``` r
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  dplyr::select(city_state, resolution, victim_age, victim_race, victim_sex)
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_double(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_double(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

Start with one city.

``` r
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  dplyr::select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

| term              |    OR | CI\_lower | CI\_upper |
| :---------------- | ----: | --------: | --------: |
| (Intercept)       | 1.363 |     0.975 |     1.907 |
| victim\_age       | 0.993 |     0.987 |     1.000 |
| victim\_raceWhite | 2.320 |     1.648 |     3.268 |
| victim\_sexMale   | 0.426 |     0.325 |     0.558 |

Try this across cities.

``` r
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  dplyr::select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  dplyr::select(city_state, term, OR, starts_with("CI")) 
```

``` r
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

<img src="p8105_hw6_cl3938_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

### Problem 2

First, let’s import and clean the data. The following steps were taken:

  - Import CSV
  - Clean names
  - Change relevant variables to factor

<!-- end list -->

``` r
#input data
baby_df = 
  read_csv("./data/birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)) 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double()
    ## )

    ## See spec(...) for full column specifications.

There are 0 missing values in the entire dataframe. This is great, so
we’ll progress to making our regression models.

Model 1: curated model

For this model, we’ll use a stepwise algorithm to automatically select
the best model from the full list of predictors. This is primarily used
as exploratory analysis: the model adds and removes predictors
iteratively based on a predetermined criteria. For my purposes, I’m
going to use Akaike Information Criteria, or AIC, a metric that is a
good balance between prioritizing model fit and also penalizing for too
many predictors.

It’s important to note that stepwise model selection results shouldn’t
be overintepreted, and there’s a great deal of uncertainty surrounding
them. I’m only going to use it to explore the data a bit, since I know
next to nothing about this field - true models should always be based in
reason & literature review.

Let’s get started\!

``` r
#Fit the full model 
full_bwt_linear.model <- lm(bwt~., data = baby_df)

#Stepwise regression model
step_bwt_linear.model <- stepAIC(full_bwt_linear.model, direction = "both", 
                      trace = FALSE)

#Display converged model
step_bwt_linear.model %>% 
  broom::tidy() %>%
  knitr::kable(digits = 3)
```

| term        |   estimate | std.error | statistic | p.value |
| :---------- | ---------: | --------: | --------: | ------: |
| (Intercept) | \-6098.822 |   137.546 |  \-44.340 |   0.000 |
| babysex2    |     28.558 |     8.455 |     3.378 |   0.001 |
| bhead       |    130.777 |     3.447 |    37.944 |   0.000 |
| blength     |     74.947 |     2.019 |    37.120 |   0.000 |
| delwt       |      4.107 |     0.392 |    10.475 |   0.000 |
| fincome     |      0.318 |     0.175 |     1.820 |   0.069 |
| gaweeks     |     11.592 |     1.462 |     7.929 |   0.000 |
| mheight     |      6.594 |     1.785 |     3.694 |   0.000 |
| mrace2      |  \-138.792 |     9.907 |  \-14.009 |   0.000 |
| mrace3      |   \-74.887 |    42.315 |   \-1.770 |   0.077 |
| mrace4      |  \-100.678 |    19.325 |   \-5.210 |   0.000 |
| parity      |     96.305 |    40.336 |     2.388 |   0.017 |
| ppwt        |    \-2.676 |     0.427 |   \-6.261 |   0.000 |
| smoken      |    \-4.843 |     0.586 |   \-8.271 |   0.000 |

``` r
#Plot the model
baby_df %>% 
  modelr::add_residuals(step_bwt_linear.model) %>% 
  modelr::add_predictions(step_bwt_linear.model) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  geom_smooth(se = F) +
  labs(
    x = "Predicted Values",
    y = "Residuals",
    title = "Residuals vs Fitted"
  )
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

<img src="p8105_hw6_cl3938_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

Other models:

  - Model 1: length at birth and gestational age as predictors (main
    effects only)

<!-- end list -->

``` r
test_1.model <- lm(bwt~gaweeks + blength, data= baby_df)

test_1.model %>% 
  broom::tidy() %>%
  knitr::kable(digits = 3)
```

| term        |   estimate | std.error | statistic | p.value |
| :---------- | ---------: | --------: | --------: | ------: |
| (Intercept) | \-4347.667 |    97.958 |  \-44.383 |       0 |
| gaweeks     |     27.047 |     1.718 |    15.744 |       0 |
| blength     |    128.556 |     1.990 |    64.604 |       0 |

  - Model 2: head circumference, length, sex, and all interactions
    (including the three-way interaction) between these

<!-- end list -->

``` r
test_2.model <- lm(bwt~babysex*bhead*blength, data = baby_df)

test_2.model %>% 
  broom::tidy() %>%
  knitr::kable(digits = 3)
```

| term                   |   estimate | std.error | statistic | p.value |
| :--------------------- | ---------: | --------: | --------: | ------: |
| (Intercept)            | \-7176.817 |  1264.840 |   \-5.674 |   0.000 |
| babysex2               |   6374.868 |  1677.767 |     3.800 |   0.000 |
| bhead                  |    181.796 |    38.054 |     4.777 |   0.000 |
| blength                |    102.127 |    26.212 |     3.896 |   0.000 |
| babysex2:bhead         |  \-198.393 |    51.092 |   \-3.883 |   0.000 |
| babysex2:blength       |  \-123.773 |    35.119 |   \-3.524 |   0.000 |
| bhead:blength          |    \-0.554 |     0.780 |   \-0.710 |   0.478 |
| babysex2:bhead:blength |      3.878 |     1.057 |     3.670 |   0.000 |

Before we do cross-validation, let’s take a look at goodness of fit of
our 3 respective models:

``` r
baby_df %>% 
  gather_predictions(step_bwt_linear.model, test_1.model, test_2.model) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```

<img src="p8105_hw6_cl3938_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

Let’s start with cross-validation\! Splitting data into training &
testing:

``` r
cv_df =
  crossv_mc(baby_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

Fitting models & obtaining RMSE values:

``` r
cv_df = 
  cv_df %>% 
  mutate(
    step_mod  = map(train, ~lm(bwt~babysex + bhead + blength + delwt + fincome + gaweeks + mrace + parity + ppwt + smoken, data = .x)),
    test1_mod = map(train, ~lm(bwt~gaweeks + blength, data = .x)),
    test2_mod = map(train, ~lm(bwt~babysex*bhead*blength, data = .x))) %>% 
  mutate(
    rmse_step = map2_dbl(step_mod, test, ~rmse(model = .x, data = .y)),
    rmse_test1  = map2_dbl(test1_mod, test, ~rmse(model = .x, data = .y)),
    rmse_test2 = map2_dbl(test2_mod, test, ~rmse(model = .x, data = .y)))
```

Okay, now let’s make our violin plots:

``` r
cv_df %>% 
  dplyr::select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

<img src="p8105_hw6_cl3938_files/figure-gfm/unnamed-chunk-12-1.png" width="90%" />

### Problem 3

Import data

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  dplyr::select(name, id, everything())
```

    ## using cached file: /Users/cynthialiu/Library/Caches/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2020-12-09 02:11:43 (7.536)

    ## file min/max dates: 1869-01-01 / 2020-12-31
